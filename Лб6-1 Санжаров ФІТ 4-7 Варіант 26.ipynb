{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторна робота №6\n",
    "## Завдання 1\n",
    "\n",
    "1. Завантаження та підготовка даних:\n",
    "    - Виберіть вбудований датасет для задачі регресії з бібліотеки scikit-learn\n",
    "(наприклад, Boston Housing, California Housing) або будь-який датасет\n",
    "для регресії.\n",
    "    - Завантажте дані та розділіть їх на навчальну та тестову вибірки\n",
    "(рекомендується використовувати співвідношення 80/20 або 70/30).\n",
    "2. Побудова регресійної моделі:\n",
    "    - Побудуйте базову лінійну регресійну модель на основі навчальної вибірки.\n",
    "    - Оцініть точність моделі на тестовій вибірці та визначте її продуктивність,\n",
    "використовуючи метрики якості регресії (наприклад, mean_squared_error,\n",
    "R^2).\n",
    "3. Аналіз перенавчання:\n",
    "    - Перевірте наявність перенавчання, порівнюючи результати на навчальній та\n",
    "тестовій вибірках. Якщо модель показує значно кращі результати на\n",
    "навчальних даних, це може свідчити про перенавчання.\n",
    "4. Запобігання перенавчанню:\n",
    "    - Введіть регуляризацію: використайте моделі з регуляризацією, такі як Ridge\n",
    "Regression або Lasso Regression.\n",
    "    - Перевірте роботу моделі з різними значеннями параметра регуляризації та\n",
    "виберіть оптимальне значення.\n",
    "    - Застосуйте крос-валідацію для більш стабільної оцінки продуктивності\n",
    "моделі.\n",
    "5. Оцінка результатів:\n",
    "    - Оцініть кінцеву продуктивність моделі на тестовій вибірці та порівняйте її з\n",
    "базовою моделлю.\n",
    "    - Проаналізуйте, як введення регуляризації та використання крос-валідації\n",
    "вплинули на якість моделі.\n",
    "6. Візуалізація та висновки:\n",
    "    - Побудуйте графіки, що демонструють залежність помилки моделі від\n",
    "гіперпараметрів регуляризації.\n",
    "    - Підготуйте звіт з висновками щодо ефективності моделі, заходів щодо\n",
    "запобігання перенавчанню та загальних результатів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. rubric:: References\n",
      "\n",
      "- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "  Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = datasets.fetch_california_housing()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704  \n",
       "std       10.386050      2.135952      2.003532  \n",
       "min        0.692308     32.540000   -124.350000  \n",
       "25%        2.429741     33.930000   -121.800000  \n",
       "50%        2.818116     34.260000   -118.490000  \n",
       "75%        3.282261     37.710000   -118.010000  \n",
       "max     1243.333333     41.950000   -114.310000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.5558915986952444\n",
      "R2 Score: 0.5757877060324508\n",
      "Accuracy: 0.5757877060324508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))\n",
    "print('Accuracy:', linear.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6125511913966952\n"
     ]
    }
   ],
   "source": [
    "# Test overfitting\n",
    "print('Accuracy:', linear.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Best Parameters: {'alpha': np.float64(1.0)}\n",
      "Lasso Best Parameters: {'alpha': np.float64(0.001)}\n",
      "Ridge CV Mean Squared Error: 0.51926515697919\n",
      "Lasso CV Mean Squared Error: 0.5192487792639193\n",
      "Ridge Mean Squared Error: 0.5558512007367515\n",
      "Ridge R2 Score: 0.5758185345441319\n",
      "Ridge Accuracy: 0.5758185345441319\n",
      "Ridge Accuracy with training data: 0.612551119993334\n",
      "Lasso Mean Squared Error: 0.5544062174455686\n",
      "Lasso R2 Score: 0.5769212309657656\n",
      "Lasso Accuracy: 0.5769212309657656\n",
      "Lasso Accuracy with training data: 0.6125069391599488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "\n",
    "parameters = {'alpha': np.logspace(-5, 2, 8)}\n",
    "\n",
    "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=5)\n",
    "ridge_regressor.fit(X_train, y_train)\n",
    "\n",
    "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=5)\n",
    "lasso_regressor.fit(X_train, y_train)\n",
    "\n",
    "print(f'Ridge Best Parameters: {ridge_regressor.best_params_}')\n",
    "print(f'Lasso Best Parameters: {lasso_regressor.best_params_}')\n",
    "\n",
    "ridge_best = Ridge(**ridge_regressor.best_params_)\n",
    "lasso_best = Lasso(**lasso_regressor.best_params_)\n",
    "\n",
    "ridge_cv_scores = cross_val_score(ridge_best, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_cv_scores = cross_val_score(lasso_best, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print('Ridge CV Mean Squared Error:', -ridge_cv_scores.mean())\n",
    "print('Lasso CV Mean Squared Error:', -lasso_cv_scores.mean())\n",
    "\n",
    "ridge_best.fit(X_train, y_train)\n",
    "lasso_best.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = ridge_best.predict(X_test)\n",
    "y_pred_lasso = lasso_best.predict(X_test)\n",
    "\n",
    "print('Ridge Mean Squared Error:', mean_squared_error(y_test, y_pred_ridge))\n",
    "print('Ridge R2 Score:', r2_score(y_test, y_pred_ridge))\n",
    "print('Ridge Accuracy:', ridge_best.score(X_test, y_test))\n",
    "print('Ridge Accuracy with training data:', ridge_best.score(X_train, y_train))\n",
    "\n",
    "print('Lasso Mean Squared Error:', mean_squared_error(y_test, y_pred_lasso))\n",
    "print('Lasso R2 Score:', r2_score(y_test, y_pred_lasso))\n",
    "print('Lasso Accuracy:', lasso_best.score(X_test, y_test))\n",
    "print('Lasso Accuracy with training data:', lasso_best.score(X_train, y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CV Mean Squared Error: 0.5192652011433679\n",
      "Ridge CV Mean Squared Error:  0.51926515697919\n",
      "Lasso CV Mean Squared Error:  0.5192487792639193\n"
     ]
    }
   ],
   "source": [
    "# Compare base linear regression with Ridge and Lasso\n",
    "# Using cross validation\n",
    "linear_cv_scores = cross_val_score(linear, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv_scores = cross_val_score(ridge_best, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_cv_scores = cross_val_score(lasso_best, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print('Linear CV Mean Squared Error:', -linear_cv_scores.mean())\n",
    "print('Ridge CV Mean Squared Error: ', -ridge_cv_scores.mean())\n",
    "print('Lasso CV Mean Squared Error: ', -lasso_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У випадку з даним датасетом перенавчення не є великою проблемою навіть з лінійною регресією. А тому навіть з регуляризацією L1 та L2, результати дужі схожі як з тестовиими так і з тренувальними даними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
